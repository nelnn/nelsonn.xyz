<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
	<title></title>
	<link>nelsonn.xyz/posts/</link>
	<description>Recent content in Posts on </description>
	<generator>Hugo -- gohugo.io</generator>
	<language>en-uk</language>
	<lastBuildDate>Wed, 04 Dec 2024 19:40:07 +0000</lastBuildDate>
    
        <atom:link href="nelsonn.xyz/posts/index.xml" rel="self" type="application/rss+xml" />
	
	
	<item>
		<title>Adaboost</title>
		<link>nelsonn.xyz/posts/adaboost/</link>
		<pubDate>Wed, 04 Dec 2024 19:40:07 +0000</pubDate>
		
		<guid>nelsonn.xyz/posts/adaboost/</guid>
		<description>&lt;p&gt;Adaboost is a boosting algorithm for binary classification, although it can be generalised to multi-class classification. A boosted classifier is just a aggregation of weaker learners (e.g. decision trees) where each one is trained on top of the previous one. Each subsequent learner is trained with a set of updated weights for the training samples, where the misclassified sampled are weighted more, or equivalently suppress the weights of the correctly classified samples, to allow the current learner to correct the mistakes made by the previous one. The final prediction is the sum of the outputs of all trees, with its sign indicating which class a sample belongs to, and the value the confidence of the prediction.&lt;/p&gt;
&lt;div class=&#34;math&#34;&gt;
I did not understand why assigning more weights to the misclassified samples would improve the learner since I thought this would misclassify the correct samples in the last round. What I didn&#39;t realise the weights for the correct samples were small such that the classifier would give an output close to 0. The aggregated sum becomes something like \(\hat y + 0.01 + -0.05 + ... \simeq \hat y\).
&lt;/div&gt;
&lt;h2 id=&#34;derivation&#34;&gt;Derivation&lt;/h2&gt;
&lt;p&gt;The following formulation follows the one in &lt;a href=&#34;https://en.wikipedia.org/wiki/AdaBoost&#34;&gt;wikipedia&lt;/a&gt;, nonetheless is useful for myself to write it out.
The aggregated classifier after \(T\) iteration, \(C_T(\bar x)\)&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, is the sum of the weak learners trained at each iteration \(t\) where&lt;/p&gt;
$$ C_{T}(\bar x) = \sum_{t=1}^T c_{t}(\bar x) $$&lt;p&gt;The final select weak learner \(f_t(\bar x)\) is actually a weighted weak learner at each iteration, such that&lt;/p&gt;
$$ c_t(t) = \alpha_t k(\bar x), $$&lt;p&gt;where \(k(\bar x)\) is the selected weak learner and \(\alpha_t\) the coefficient associated to the weak learner that minimizes the loss function:&lt;/p&gt;
$$ E_t = \sum_i E[C_{t-1}(\bar x_i) + \alpha_t k(\bar x_i)] $$&lt;p&gt;Suppose we have a dataset \(\left\{(\bar x_1, y_1), ..., (\bar x_N, y_N)\right\}\), where \(y \in \left\{-1, 1\right\}\) and a set of weak classifiers \(\left\{k_1, ..., k_L\right\},\) and \(k_j(\bar x_i) \in \left\{1, 1\right\}\). The boosted classifier after \(m-1\) iteration is then:&lt;/p&gt;
$$ C_{(m-1)}(\bar x_{i})=\alpha_{1}k_{1}(\bar x_{i})+\cdot\cdot\cdot+\alpha_{m-1}k_{m-1}(x_{i}) $$&lt;p&gt;It follows that&lt;/p&gt;
$$ C_m(x_i) = C_{m-1}(x_i) + \alpha_m k_m (x_i) $$&lt;p&gt;All we need to do now is to get the best \(k_m\) by minimising the loss function. In Adaboost, we use an exponential loss on each data point&lt;/p&gt;
$$ E=\sum_{i=1}^{N}e^{-y_{i}C_{m}(\bar x_{i})}=\sum_{i=1}^{N}e^{-y_{i}C_{(m-1)}(\bar x_{i})}e^{-y_{i}\alpha_{m}k_{m}(\bar x_{i})} $$&lt;p&gt;If \(C_m(\bar x_i) = y_i\) then the loss will be \(e^{-1}\), otherwise \(e^1\). We can factorise the right and wrong predictions:&lt;/p&gt;
$$
\begin{align}
E &amp;= \sum_{y_i=k_m(\bar x_i)} w_{i}^{(m)} e^{-\alpha_m} + \sum_{y_i \neq k_m(\bar x_i)} w_{i}^{(m)} e^{\alpha_m} \nonumber \\
  &amp;= \sum_{i=1}^{N} w_{i}^{(m)} e^{-\alpha_m} + \sum_{y_i \neq k_m(\bar x_i)} w_i^{(m)} (e^{\alpha_m} - e^{-\alpha_m})\nonumber
\end{align}
$$&lt;p&gt;where \(w_i^{(1)} = 1\) and \(w_{i}^{(m)} = e^{-y_i C_{m-1}(\bar x_i)}\) for \(m &gt; 1\). We also use the fact \(y_i k_m(\bar x_i) = 1\) for the correct predictions.&lt;/p&gt;
&lt;p&gt;Differentiating \(E\) with respect to \(\alpha_m\) and set it to \(0\) gives&lt;/p&gt;
$$ \alpha_m = \frac{1}{2} \ln\left(\frac{\sum_{y_i=k_m(\bar x_i)} w_i^{(m)}}{\sum_{y_i \neq k_m(\bar x_i)} w_i^{(m)}}\right) $$&lt;p&gt;Since the weighted error rate of the weak classifier is \(w_i^{(m)}\) for \(m &gt; 1\), the error rate is&lt;/p&gt;
$$ \epsilon_{m}\,=\,\frac{\sum_{y_{i}\neq k_{m}(x_{i})}\,w_{i}^{(m)}}{\sum_{i=1}^{N}\,w_{i}^{(m)}} $$&lt;p&gt;We can now conclude \(\alpha\) to be&lt;/p&gt;
$$ \alpha_m = \frac{1}{2} \ln \left(\frac{1-\epsilon_m}{\epsilon_m}\right) $$&lt;h2 id=&#34;adaboost-algorithm&#34;&gt;Adaboost Algorithm&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Initialise the observation weights \(w_i = \frac{1}{n}, i = 1,2,...,n\).&lt;/li&gt;
&lt;li&gt;For m = 1 to M:
&lt;ol&gt;
&lt;li&gt;Fit a classifier \(k^{(m)}(\bar x)\) to the traning data using weight \(w_i\).&lt;/li&gt;
&lt;li&gt;Compute the weighted error rate \(\epsilon_m\)&lt;/li&gt;
&lt;li&gt;Compute \(\alpha_m\)&lt;/li&gt;
&lt;li&gt;Set the new weight \(w_{i} \leftarrow w_{i} e^{-y_i \alpha_m h_m(\bar x)}\)&lt;/li&gt;
&lt;li&gt;Renormalise \(w_i\) such that \(\sum_i w_i = 1\)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Output \(C(\bar x) = \sum_{m=1}^{M} \alpha_m h_m(\bar x)\)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;multi-class-adaboost-algorithm&#34;&gt;Multi-class Adaboost Algorithm&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://hastie.su.domains/Papers/samme.pdf&#34;&gt;This paper&lt;/a&gt; suggests a simple twist to allow Adaboost to be used for multi-class classification. The algorithm is exactly the same except now \(\alpha_m\) is changed to&lt;/p&gt;
$$ \alpha_m = \log \frac{1 - \epsilon_m}{\epsilon_m} + \log (K - 1)$$&lt;p&gt;where \(K &gt; 1\) is the number of classes. This algorithm is implemented in &lt;a href=&#34;https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_multiclass.html&#34;&gt;scikit-learn&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;I use a bar on top of a variable to denote it is a vector.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
	</item>
	
	<item>
		<title>Tryfan</title>
		<link>nelsonn.xyz/leisure/tryfan/</link>
		<pubDate>Tue, 19 Nov 2024 22:01:48 +0000</pubDate>
		
		<guid>nelsonn.xyz/leisure/tryfan/</guid>
		<description>&lt;p&gt;I went to visit Jake up North the last weekend and he decided we should climb Tryfan. It took us two hours of driving to get there in the Saturday morning and arrived at 10-ish. The weather wasn&amp;rsquo;t the nicest but the hike shouldn&amp;rsquo;t be too hard right? After all I bought a pair of Goretex Boots which cost Â£100 and felt prepared. And boy I was wrong.&lt;/p&gt;
&lt;p&gt;Less than 30 minutes in I started to doubt whether I could get to the summit. I was gased and had to stop frequently to catch my breath. The path was nowhere as hard as what was coming next, but for the pace we ascend I ran out of oxygen very quickly. My heart rate was probably over 180 during this period.

&lt;figure class=&#34;img&#34;&gt;&lt;img src=&#34;images/1.jpg&#34;&gt;&lt;figcaption&gt;Begining of the climb. It was raining and foggy.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;After awhile my heart rate settled down and the rest of the hike I didn&amp;rsquo;t feel too tired whilst the climb was more challenging.

&lt;figure class=&#34;img&#34;&gt;&lt;img src=&#34;images/2.jpg&#34;&gt;&lt;figcaption&gt;The rocks were very slippery&lt;/figcaption&gt;&lt;/figure&gt;


&lt;figure class=&#34;img&#34;&gt;&lt;img src=&#34;images/3.jpg&#34;&gt;&lt;figcaption&gt;Top of a gullt to get over the North ridge.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;br&gt;

&lt;figure class=&#34;img&#34;&gt;&lt;img src=&#34;images/4.jpg&#34;&gt;&lt;figcaption&gt;The summit. Nice view..&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;figure class=&#34;img&#34;&gt;&lt;img src=&#34;images/6.jpg&#34;&gt;&lt;figcaption&gt;The fog cleared out when we came down to the lake. We sat down and had our sandwiches.&lt;/figcaption&gt;&lt;/figure&gt;


&lt;figure class=&#34;img&#34;&gt;&lt;img src=&#34;images/7.jpg&#34;&gt;&lt;figcaption&gt;Landscape.&lt;/figcaption&gt;&lt;/figure&gt;


&lt;figure class=&#34;img&#34;&gt;&lt;img src=&#34;images/8.jpg&#34;&gt;&lt;figcaption&gt;Me.&lt;/figcaption&gt;&lt;/figure&gt;


&lt;figure class=&#34;img&#34;&gt;&lt;img src=&#34;images/9.jpg&#34;&gt;&lt;figcaption&gt;On our way back to our car.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
	</item>
	
	<item>
		<title>Movie List</title>
		<link>nelsonn.xyz/posts/movie_list/</link>
		<pubDate>Sat, 12 Oct 2024 13:23:21 +0100</pubDate>
		
		<guid>nelsonn.xyz/posts/movie_list/</guid>
		<description>&lt;p&gt;I use ChatGPT to format the list below so I don&amp;rsquo;t need to manually look for year, directors and actors and type them out. Obviously I have watched a lot more and I will slowly add them to the list.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Trainspotting&lt;/strong&gt; (1996)&lt;br&gt;
&lt;em&gt;Director:&lt;/em&gt; Danny Boyle&lt;br&gt;
&lt;em&gt;Main Actors:&lt;/em&gt; Ewan McGregor, Ewen Bremner, Jonny Lee Miller, Kevin McKidd, Robert Carlyle and Kelly Macdonald&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Se7en&lt;/strong&gt; (1995)&lt;br&gt;
&lt;em&gt;Director:&lt;/em&gt; David Fincher&lt;br&gt;
&lt;em&gt;Main Actors:&lt;/em&gt; Morgan Freeman, Brad Pitt, Kevin Spacey&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Gone Girl&lt;/strong&gt; (2014)&lt;br&gt;
&lt;em&gt;Director:&lt;/em&gt; David Fincher&lt;br&gt;
&lt;em&gt;Main Actors:&lt;/em&gt; Ben Affleck, Rosamund Pike, Neil Patrick Harris&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;American Psycho&lt;/strong&gt; (2000)&lt;br&gt;
&lt;em&gt;Director:&lt;/em&gt; Mary Harron&lt;br&gt;
&lt;em&gt;Main Actors:&lt;/em&gt; Christian Bale, Justin Theroux, Willem Dafoe&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Inception&lt;/strong&gt; (2010)&lt;br&gt;
&lt;em&gt;Director:&lt;/em&gt; Christopher Nolan&lt;br&gt;
&lt;em&gt;Main Actors:&lt;/em&gt; Leonardo DiCaprio, Joseph Gordon-Levitt, Ellen Page&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Interstellar&lt;/strong&gt; (2014)&lt;br&gt;
&lt;em&gt;Director:&lt;/em&gt; Christopher Nolan&lt;br&gt;
&lt;em&gt;Main Actors:&lt;/em&gt; Matthew McConaughey, Anne Hathaway, Jessica Chastain&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The Batman Trilogy&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Batman Begins&lt;/em&gt; (2005)&lt;br&gt;
&lt;em&gt;Director:&lt;/em&gt; Christopher Nolan&lt;br&gt;
&lt;em&gt;Main Actors:&lt;/em&gt; Christian Bale, Michael Caine, Liam Neeson&lt;/li&gt;
&lt;li&gt;&lt;em&gt;The Dark Knight&lt;/em&gt; (2008)&lt;br&gt;
&lt;em&gt;Director:&lt;/em&gt; Christopher Nolan&lt;br&gt;
&lt;em&gt;Main Actors:&lt;/em&gt; Christian Bale, Heath Ledger, Aaron Eckhart&lt;/li&gt;
&lt;li&gt;&lt;em&gt;The Dark Knight Rises&lt;/em&gt; (2012)&lt;br&gt;
&lt;em&gt;Director:&lt;/em&gt; Christopher Nolan&lt;br&gt;
&lt;em&gt;Main Actors:&lt;/em&gt; Christian Bale, Tom Hardy, Anne Hathaway&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Blood Diamond&lt;/strong&gt; (2006)&lt;br&gt;
&lt;em&gt;Director:&lt;/em&gt; Edward Zwick&lt;br&gt;
&lt;em&gt;Main Actors:&lt;/em&gt; Leonardo DiCaprio, Djimon Hounsou, Jennifer Connelly&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Arrival&lt;/strong&gt; (2016)&lt;br&gt;
&lt;em&gt;Director:&lt;/em&gt; Denis Villeneuve&lt;br&gt;
&lt;em&gt;Main Actors:&lt;/em&gt; Amy Adams, Jeremy Renner, Forest Whitaker&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
	</item>
	
	<item>
		<title>rsync</title>
		<link>nelsonn.xyz/posts/rsync/</link>
		<pubDate>Wed, 09 Oct 2024 21:48:36 +0100</pubDate>
		
		<guid>nelsonn.xyz/posts/rsync/</guid>
		<description>&lt;p&gt;If you don&amp;rsquo;t know about rsync, you should get to know it now. Rsync is a Linux utility that allows you to backup files and directories to either a remote or local server. You can even stop syncing and be able to resume without starting over because rsync can pick up where if left off.&lt;/p&gt;
&lt;p&gt;Basic usage copied from the &lt;code&gt;man&lt;/code&gt; page:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rsync -t *.c foo:src/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This would transfer all files matching the pattern *.c from the current directory to the directory src on the machine foo. If any of the files already exist on the remote system then the rsync remote-update protocol is used to update the file by sending only the differences. See the tech report for details.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rsync -avz foo:src/bar /data/tmp
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This would recursively transfer all files from the directory src/bar on the machine foo into the
/data/tmp/bar directory on the local machine. The files are transferred in &amp;ldquo;archive&amp;rdquo; mode, which ensures
that symbolic links, devices, attributes, permissions, ownerships, etc. are preserved in the transfer.
Additionally, compression will be used to reduce the size of data portions of the transfer.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rsync -avz foo:src/bar/ /data/tmp
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A trailing slash on the source changes this behavior to avoid creating an additional directory level at the destination.  You can think of a trailing / on a source as meaning &amp;ldquo;copy the contents of this directory&amp;rdquo; as opposed to &amp;ldquo;copy the directory by name&amp;rdquo;, but in both cases the attributes of the containing directory are transferred to the containing directory on the destination.&lt;/p&gt;
&lt;p&gt;You can do this with a local machine of the same network. For example, to transfer files between two Macbooks, first enable &lt;em&gt;Remote Login&lt;/em&gt; (assuming macOS Sonoma) in Settings -&amp;gt; General -&amp;gt; Sharing -&amp;gt; Advanced -&amp;gt; toggle the Remote Login option on the received end. At the bottom of the page you can see the local host name, we need that to send the files. Now, on the other computer we can just run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rsync &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;option&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; /src/foo/ username@localhostname:/data/foo
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can check out the full documentation by typing &lt;code&gt;man rsync&lt;/code&gt; in the terminal.&lt;/p&gt;
</description>
	</item>
	
	<item>
		<title>My Workout Split</title>
		<link>nelsonn.xyz/posts/workout_split/</link>
		<pubDate>Wed, 02 Oct 2024 19:59:34 +0100</pubDate>
		
		<guid>nelsonn.xyz/posts/workout_split/</guid>
		<description>&lt;p&gt;I don&amp;rsquo;t really split my workout across the week by push, pull, leg, or upper and lower body split. First of all I should state what works for me might not be the best for you, and you will need to experiment to find out. Second of all my goal is not hypertrophy but strength. &lt;strong&gt;Gains are only by-products.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Like many gym newbiews, I was first introduced to the &amp;ldquo;Push-Pull-Leg&amp;rdquo; Split. It sounds like a solid workout plan because it hits all muscle groups at least twice a week. It may work well for you for a good while, especially if you have just started, but soon you will hit the wall (at least I did).&lt;/p&gt;
&lt;p&gt;So this is what I do:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;For each session, I focus on 1-2 compound exercises that target different muscle groups with maximum effort, or 1 compound and 1 calisthentics exercise.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Compound exercises are bench press, overhead press, squat, hip thrust, deadlift, weighted pull-ups and weighted dips.&lt;/p&gt;
&lt;p&gt;If you maxed out on squat as the first exercise, you should not be able to lift a 100% for leg press. Therefore, it would be far more efficient in my opinion to then push hard for an upper body exercise and then finish off with arms or abs or even stretching if you have time.&lt;/p&gt;
&lt;p&gt;It works so well for me because the big muscle groups do not get overworked so I can almost push close to my limit every time. Yes it may sacrifice gains but you get stronger quicker, which helps you getting bigger ultimately.&lt;/p&gt;
&lt;p&gt;Currently my body weight is around 70kg. My PR for bench is 100kg x 3, squat 130kg x 2, weighted pull-ups 20kg x 6, weighted dips 45kg x 5, deadlift 140kg x 2 (weakest lift due to back issue), hip thrust 160kg x 5, overhead press 60kg x 5.&lt;/p&gt;
&lt;p&gt;For calisthenics, I can do 5 muscle-ups with decent form (no kipping), back lever for 15-20 seconds, front lever straddle for 8-10 seconds, 1 handstand push-up, 5-10 seconds handstand hold, 2-3 ring muscle-ups.&lt;/p&gt;
</description>
	</item>
	
	</channel>
</rss>
